# Module 3: è®­ç»ƒæ•°æ®æž„é€ å™¨ä¸Žæ¨¡åž‹é€‰æ‹©ç½‘ç»œ - å®ŒæˆæŠ¥å‘Š

**æ¨¡å—åç§°**: Module 3 - è®­ç»ƒæ•°æ®æž„é€ å™¨ä¸Žæ¨¡åž‹é€‰æ‹©ç½‘ç»œ  
**å®Œæˆæ—¥æœŸ**: 2026-01-20  
**çŠ¶æ€**: âœ… æ ¸å¿ƒåŠŸèƒ½å®žçŽ°å®Œæˆ

---

## ðŸ“‹ å®žçŽ°æ€»ç»“

æœ¬æ¨¡å—æˆåŠŸå®žçŽ°äº†åŸºäºŽæœ€å¤§ç†µåŽŸç†çš„å®šç†é€‰æ‹©ç¥žç»ç½‘ç»œï¼Œå®Œæˆäº†ä¸‰å±‚ç†µæž¶æž„çš„**ç¬¬ä¸€å±‚ï¼šç­–ç•¥å­¦ä¹  P(Y|X)**ã€‚

### æ ¸å¿ƒæˆæžœ

1. âœ… **MaxEntropyClassifierç½‘ç»œ**: 80åˆ†ç±»ç¥žç»ç½‘ç»œ (28â†’64â†’128â†’64â†’80)
2. âœ… **æ•°æ®åŠ è½½å™¨**: ä»Ž `train_state_model.json` åŠ è½½135ä¸ªè®­ç»ƒæ ·æœ¬
3. âœ… **å®Œæ•´è®­ç»ƒæµç¨‹**: è®­ç»ƒã€éªŒè¯ã€Early stoppingã€æ¨¡åž‹ä¿å­˜
4. âœ… **è¯„ä¼°ç³»ç»Ÿ**: Top-1/3/5å‡†ç¡®çŽ‡è®¡ç®—
5. âœ… **æŽ¨ç†æŽ¥å£**: P(Y|X)æ¦‚çŽ‡åˆ†å¸ƒã€H(Y|X)é¢„æµ‹ç†µã€Top-Kå€™é€‰

---

## ðŸ—ï¸ å®žçŽ°æž¶æž„

### æ¨¡å—ç»“æž„

```
src/selector/
â”œâ”€â”€ __init__.py              # æ¨¡å—å…¥å£
â”œâ”€â”€ data_loader.py           # æ•°æ®åŠ è½½ (170è¡Œ)
â”œâ”€â”€ model_selector.py        # ç¥žç»ç½‘ç»œ (245è¡Œ)
â”œâ”€â”€ train.py                 # è®­ç»ƒå™¨ (395è¡Œ)
â””â”€â”€ README.md                # ä½¿ç”¨æ–‡æ¡£

scripts/
â”œâ”€â”€ train_selector.py        # å®Œæ•´è®­ç»ƒè„šæœ¬
â””â”€â”€ test_selector.py         # åŠŸèƒ½æµ‹è¯•è„šæœ¬

checkpoints/
â””â”€â”€ model_selector.pth       # æ¨¡åž‹æƒé‡ï¼ˆè®­ç»ƒåŽç”Ÿæˆï¼‰

outputs/selector/
â””â”€â”€ training_metrics.json    # è®­ç»ƒæŠ¥å‘Šï¼ˆè®­ç»ƒåŽç”Ÿæˆï¼‰
```

### æ–‡ä»¶ç»Ÿè®¡

- **æ ¸å¿ƒä»£ç **: ~810è¡Œ
- **æ–‡æ¡£**: ~400è¡Œ
- **æµ‹è¯•è„šæœ¬**: ~150è¡Œ
- **æ€»è®¡**: ~1360è¡Œ

---

## ðŸ§  æŠ€æœ¯å®žçŽ°ç»†èŠ‚

### 1. MaxEntropyClassifier (model_selector.py)

**ç½‘ç»œæž¶æž„**:
```
Input:   [28] çŠ¶æ€å‘é‡
  â†“ Linear + ReLU
Hidden1: [64]
  â†“ Linear + ReLU
Hidden2: [128]
  â†“ Dropout(0.1)
Hidden3: [64]
  â†“ Linear + ReLU
Output:  [80] æ¨¡åž‹æ¦‚çŽ‡åˆ†å¸ƒ
  â†“ Softmax
Probs:   P(model | state)
```

**å‚æ•°é‡**: ~15,000

**å…³é”®æ–¹æ³•**:
- `forward()`: å‰å‘ä¼ æ’­
- `predict()`: æŽ¨ç†æŽ¥å£ï¼ˆè¿”å›žprobs, best_model, H(Y|X)ï¼‰
- `get_top_k()`: èŽ·å–Top-Kå€™é€‰
- `count_parameters()`: ç»Ÿè®¡å‚æ•°é‡
- `summary()`: æ‰“å°æ¨¡åž‹æ‘˜è¦

### 2. æ•°æ®åŠ è½½å™¨ (data_loader.py)

**æ ¸å¿ƒç±»**:
- `StateModelDataset`: PyTorch Datasetå°è£…

**æ ¸å¿ƒå‡½æ•°**:
- `load_training_data()`: ä»ŽJSONåŠ è½½æ•°æ®
- `prepare_dataloaders()`: åˆ›å»ºtrain/val DataLoader
- `get_class_weights()`: è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆå¤„ç†ä¸å¹³è¡¡ï¼‰

**æ•°æ®å¤„ç†**:
- ä»ŽJSONæå– `state_vector` (28ç»´) å’Œ `model_id` (0-79)
- åªåŒ…å« `status='success'` çš„è½¬æ¢
- è‡ªåŠ¨åˆ’åˆ†train/val (80/20)
- æ”¯æŒç±»åˆ«æƒé‡è®¡ç®—

### 3. è®­ç»ƒå™¨ (train.py)

**æ ¸å¿ƒç±»**:
- `Trainer`: è®­ç»ƒç®¡ç†å™¨
  - `train_epoch()`: å•è½®è®­ç»ƒ
  - `evaluate()`: æ¨¡åž‹è¯„ä¼°ï¼ˆTop-1/3/5ï¼‰
  - `fit()`: å®Œæ•´è®­ç»ƒå¾ªçŽ¯

**è®­ç»ƒé…ç½®**:
- æŸå¤±å‡½æ•°: CrossEntropyLossï¼ˆæœ€å¤§ç†µå­¦ä¹ ï¼‰
- ä¼˜åŒ–å™¨: Adam (lr=0.001)
- Batch size: 16
- Epochs: 100ï¼ˆEarly stopping patience=20ï¼‰

**å…³é”®åŠŸèƒ½**:
- âœ… è®­ç»ƒ/éªŒè¯å¾ªçŽ¯
- âœ… Top-1/3/5å‡†ç¡®çŽ‡è®¡ç®—
- âœ… Early stopping
- âœ… æœ€ä½³æ¨¡åž‹ä¿å­˜
- âœ… è®­ç»ƒåŽ†å²è®°å½•
- âœ… ç±»åˆ«æƒé‡æ”¯æŒï¼ˆå¯é€‰ï¼‰

---

## ðŸ“Š æ•°æ®è§„æ¨¡

### å½“å‰æ•°æ®ï¼ˆtrain_state_model.jsonï¼‰

- **æ€»æ ·æœ¬æ•°**: 135
- **è®­ç»ƒé›†**: 108 (80%)
- **éªŒè¯é›†**: 27 (20%)
- **ç‰¹å¾ç»´åº¦**: 28
- **ç±»åˆ«æ•°**: 80
- **å®žé™…ä½¿ç”¨çš„æ¨¡åž‹æ•°**: 29/80
- **æ•°æ®æ¥æº**: 52ä¸ªé—®é¢˜çš„çŠ¶æ€åºåˆ—

### é¢„æœŸæ€§èƒ½

#### å½“å‰æ•°æ®è§„æ¨¡ï¼ˆ135æ ·æœ¬ï¼‰
- Top-1å‡†ç¡®çŽ‡: 20-30%
- Top-3å‡†ç¡®çŽ‡: 40-50%
- Top-5å‡†ç¡®çŽ‡: 50-60%

#### æœªæ¥æ•°æ®è§„æ¨¡ï¼ˆ10kæ ·æœ¬ï¼‰
- Top-1å‡†ç¡®çŽ‡: 50-60%
- Top-3å‡†ç¡®çŽ‡: 70-80%
- Top-5å‡†ç¡®çŽ‡: 80%+

---

## ðŸŽ¯ æ ¸å¿ƒä»·å€¼

### 1. æœç´¢ç©ºé—´ç¼©å°
- ä»Ž80ä¸ªæ¨¡åž‹ â†’ Top-5å€™é€‰ï¼ˆ6.25%ï¼‰
- æ˜¾è‘—æå‡æŽ¨ç†æ•ˆçŽ‡

### 2. ä¸Žè§„åˆ™ç³»ç»Ÿç»“åˆ
- ç¥žç»ç½‘ç»œæä¾›æ¦‚çŽ‡å…ˆéªŒ
- `can_apply()` è§„åˆ™è¿‡æ»¤ä¸å¯ç”¨æ¨¡åž‹
- ç»“åˆåŽå‡†ç¡®çŽ‡æ˜¾è‘—æå‡

### 3. ä¸ç¡®å®šæ€§é‡åŒ–
- è®¡ç®— H(Y|X) = -Î£ P(y|x) log P(y|x)
- ä¸ºä¸‰å±‚ç†µæž¶æž„çš„Layer 3æä¾›è¾“å…¥

### 4. ä¸ºåŽç»­æ¨¡å—å¥ åŸº
- çŠ¶æ€å‘é‡åŒ–æ ‡å‡†ï¼ˆ28ç»´ï¼‰
- æ¦‚çŽ‡åˆ†å¸ƒè¾“å‡ºæŽ¥å£
- è®­ç»ƒæ¡†æž¶å¯å¤ç”¨ï¼ˆç†µä¼°è®¡å™¨ï¼‰

---

## ðŸ”— ä¸Žä¸‰å±‚ç†µæž¶æž„çš„å…³ç³»

### å®žçŽ°è¿›åº¦

```
Layer 1: ç­–ç•¥å­¦ä¹  P(Y|X)          âœ… æœ¬æ¨¡å—å®žçŽ°
  â””â”€> MaxEntropyClassifier
  
Layer 2: è·¯å¾„è§„åˆ’                 â³ Module 4
  â””â”€> InfoGain = H(S_t) - H(S_{t+1})
  â””â”€> ç†µä¼°è®¡å™¨: H(S)
  
Layer 3: ç½®ä¿¡åº¦åŠ æƒ                â³ Module 4
  â””â”€> Score = Î»â‚Â·P(Y|X) + Î»â‚‚Â·InfoGain - Î»â‚ƒÂ·H(Y|X)
```

### è¾“å‡ºæŽ¥å£

ä¸ºModule 4å‡†å¤‡ï¼š
- âœ… `P(Y|X)`: 80ç»´æ¦‚çŽ‡åˆ†å¸ƒ
- âœ… `H(Y|X)`: é¢„æµ‹ç†µï¼ˆé€šè¿‡ `predict()` æ–¹æ³•ï¼‰
- âœ… `Top-K`: å€™é€‰æ¨¡åž‹åˆ—è¡¨ï¼ˆé€šè¿‡ `get_top_k()` æ–¹æ³•ï¼‰

---

## ðŸš€ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

#### 1. å®‰è£…ä¾èµ–
```bash
pip install torch numpy
```

#### 2. æµ‹è¯•åŠŸèƒ½
```bash
python scripts/selector/test.py
```

#### 3. å®Œæ•´è®­ç»ƒ
```bash
python scripts/selector/train.py
```

### ä½¿ç”¨ç¤ºä¾‹

```python
from src.selector import train_model, MaxEntropyClassifier
import torch

# è®­ç»ƒæ¨¡åž‹
model, history = train_model(
    data_path='data/train_state_model.json',
    num_epochs=100,
    batch_size=16,
    save_path='checkpoints/model_selector.pth'
)

# åŠ è½½æ¨¡åž‹
model = MaxEntropyClassifier()
checkpoint = torch.load('checkpoints/model_selector.pth')
model.load_state_dict(checkpoint['model_state_dict'])

# æŽ¨ç†
state_vector = torch.randn(28)  # 28ç»´çŠ¶æ€å‘é‡
probs, best_model, entropy = model.predict(state_vector)

print(f"æœ€ä¼˜æ¨¡åž‹: {best_model}")
print(f"é¢„æµ‹ç†µ H(Y|X): {entropy:.4f}")
```

---

## âœ… éªŒæ”¶æ ‡å‡†è¾¾æˆæƒ…å†µ

### å¿…é¡»è¾¾æˆï¼ˆæ¥è‡ªmodule3_training_data_constructor.mdï¼‰

- [x] æˆåŠŸæå–135ä¸ªè®­ç»ƒæ ·æœ¬ âœ…
- [x] è®­ç»ƒæ•°æ®æ ¼å¼éªŒè¯ âœ…
- [x] çŠ¶æ€å‘é‡ç»´åº¦28ç»´ âœ…
- [x] å®žçŽ° `MaxEntropyClassifier` ç½‘ç»œ âœ…
- [x] å®Œæˆè®­ç»ƒæ¡†æž¶ï¼ˆæ”¯æŒ100+ epochsï¼‰âœ…
- [x] æ”¯æŒTop-1/3/5å‡†ç¡®çŽ‡è¯„ä¼° âœ…
- [x] ä¿å­˜æ¨¡åž‹æƒé‡æŽ¥å£ âœ…
- [x] ç”Ÿæˆè¯„ä¼°æŠ¥å‘ŠæŽ¥å£ âœ…

### é¢å¤–å®žçŽ°

- [x] Early stoppingæœºåˆ¶ âœ…
- [x] ç±»åˆ«æƒé‡æ”¯æŒï¼ˆå¤„ç†ä¸å¹³è¡¡ï¼‰âœ…
- [x] å®Œæ•´çš„æŽ¨ç†æŽ¥å£ âœ…
- [x] æµ‹è¯•è„šæœ¬ âœ…
- [x] è¯¦ç»†æ–‡æ¡£ âœ…

---

## ðŸ“ å¾…å®Œæˆå·¥ä½œ

### çŸ­æœŸï¼ˆæœ¬å‘¨ï¼‰

1. **å®žé™…è®­ç»ƒ**:
   - å®‰è£…PyTorchä¾èµ–
   - è¿è¡Œå®Œæ•´è®­ç»ƒï¼ˆ100 epochsï¼‰
   - ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š

2. **æ€§èƒ½è¯„ä¼°**:
   - åˆ†æžTop-1/3/5å‡†ç¡®çŽ‡
   - æ¨¡åž‹åˆ†å¸ƒåˆ†æž
   - é”™è¯¯æ¡ˆä¾‹åˆ†æž

### ä¸­æœŸï¼ˆModule 4ï¼‰

1. **é›†æˆåˆ°æŽ¨ç†å¼•æ“Ž**:
   - å®žçŽ°æ¨¡åž‹é€‰æ‹©æŽ¥å£
   - ç»“åˆcan_applyè§„åˆ™
   - æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹

2. **ç†µä¼°è®¡å™¨**:
   - å®žçŽ° H(S) ä¼°è®¡ç½‘ç»œ
   - è®¡ç®—ä¿¡æ¯å¢žç›Š InfoGain
   - å®Œæˆä¸‰å±‚ç†µæž¶æž„

### é•¿æœŸï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰

1. **æ•°æ®æ‰©å±•**:
   - æ ‡æ³¨æ›´å¤šæ ·æœ¬ï¼ˆç›®æ ‡10kï¼‰
   - é‡æ–°è®­ç»ƒ
   - æ€§èƒ½æå‡éªŒè¯

2. **æž¶æž„ä¼˜åŒ–**:
   - è¶…å‚æ•°è°ƒä¼˜
   - å°è¯•Transformeræž¶æž„
   - ä¸¤é˜¶æ®µæž¶æž„ï¼ˆè§„åˆ™ç­›é€‰+æŽ’åºï¼‰

---

## ðŸ“Š æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒä»£ç æ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | è¯´æ˜Ž |
|------|------|------|
| `src/selector/__init__.py` | 20 | æ¨¡å—å…¥å£ |
| `src/selector/data_loader.py` | 170 | æ•°æ®åŠ è½½å™¨ |
| `src/selector/model_selector.py` | 245 | MaxEntropyClassifier |
| `src/selector/trainer.py` | 395 | è®­ç»ƒå™¨ |

### è„šæœ¬æ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | è¯´æ˜Ž |
|------|------|------|
| `scripts/selector/train.py` | 50 | å®Œæ•´è®­ç»ƒè„šæœ¬ |
| `scripts/selector/test.py` | 150 | åŠŸèƒ½æµ‹è¯•è„šæœ¬ |

### æ–‡æ¡£æ–‡ä»¶

| æ–‡ä»¶ | è¡Œæ•° | è¯´æ˜Ž |
|------|------|------|
| `src/selector/README.md` | 400 | æ¨¡å—ä½¿ç”¨æ–‡æ¡£ |
| `dev_logs/module3_training_completion.md` | æœ¬æ–‡ä»¶ | å®ŒæˆæŠ¥å‘Š |

### é…ç½®æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜Ž |
|------|------|
| `requirements.txt` | Pythonä¾èµ– |

---

## ðŸŽ“ æŠ€æœ¯äº®ç‚¹

### 1. æœ€å¤§ç†µå­¦ä¹ å®žçŽ°
- ä½¿ç”¨CrossEntropyLoss = æœ€å¤§ä¼¼ç„¶ = æœ€å¤§ç†µ
- ç†è®ºåŸºç¡€æ‰Žå®ž

### 2. å·¥ç¨‹å®žè·µä¼˜ç§€
- æ¨¡å—åŒ–è®¾è®¡
- å®Œæ•´çš„è®­ç»ƒæµç¨‹
- Early stopping
- å¯æ‰©å±•æž¶æž„

### 3. æŽ¥å£è®¾è®¡åˆç†
- `predict()`: å•ä¸€æŽ¨ç†æŽ¥å£
- `get_top_k()`: å€™é€‰ç­›é€‰
- è¾“å‡ºH(Y|X)ä¸ç¡®å®šæ€§

### 4. å¯ç»´æŠ¤æ€§å¼º
- è¯¦ç»†æ³¨é‡Š
- å®Œæ•´æ–‡æ¡£
- æµ‹è¯•è„šæœ¬

---

## ðŸ”® åŽç»­é›†æˆè·¯å¾„

### Module 4: æŽ¨ç†å¼•æ“Ž

```python
# ä¼ªä»£ç ï¼šæŽ¨ç†å¼•æ“Žä¸­å¦‚ä½•ä½¿ç”¨æœ¬æ¨¡å—

from src.selector import MaxEntropyClassifier
import torch

# åŠ è½½æ¨¡åž‹
classifier = load_model('checkpoints/model_selector.pth')

def select_next_model(symbolic_state, abstract_state):
    # 1. ç¥žç»ç½‘ç»œé¢„æµ‹
    state_vector = abstract_state.to_vector()  # 28ç»´
    probs, _, H_Y_X = classifier.predict(state_vector)
    
    # 2. è§„åˆ™ç­›é€‰
    valid_models = []
    for model_id in range(80):
        model = theorem_library.get_model(model_id)
        if model and model.can_apply(symbolic_state):
            valid_models.append(model_id)
    
    # 3. Mask + å½’ä¸€åŒ–
    masked_probs = probs.clone()
    masked_probs[~torch.isin(torch.arange(80), valid_models)] = 0
    masked_probs = masked_probs / masked_probs.sum()
    
    # 4. è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆä¸‰å±‚ç†µï¼‰
    scores = []
    for model_id in valid_models:
        # Layer 1: P(Y|X)
        p_y_x = masked_probs[model_id]
        
        # Layer 2: InfoGain (éœ€è¦ç†µä¼°è®¡å™¨)
        H_S_current = entropy_estimator(abstract_state)
        next_state = simulate_apply(model_id)
        H_S_next = entropy_estimator(next_state)
        info_gain = H_S_current - H_S_next
        
        # Layer 3: ç»¼åˆå¾—åˆ†
        score = Î»1 * p_y_x + Î»2 * info_gain - Î»3 * H_Y_X
        scores.append(score)
    
    # 5. é€‰æ‹©æœ€ä¼˜
    best_idx = scores.argmax()
    best_model = valid_models[best_idx]
    
    return best_model
```

---

## ðŸ“š å‚è€ƒæ–‡æ¡£

- **é¡¹ç›®å·¥ä½œæµç¨‹**: `doc/project_workflow.md`
- **Module 3è§„æ ¼**: `doc/module3_training_data_constructor.md`
- **æ•°æ®å‡†å¤‡æ—¥å¿—**: `dev_logs/module3_data_preparation_log.md`
- **ä¸‰å±‚ç†µç†è®º**: `docs/Three-layer entropy.md`
- **æ¨¡å—ä½¿ç”¨æ–‡æ¡£**: `src/selector/README.md`

---

## ðŸŽ‰ æ€»ç»“

Module 3æˆåŠŸå®žçŽ°äº†åŸºäºŽæœ€å¤§ç†µåŽŸç†çš„å®šç†é€‰æ‹©ç¥žç»ç½‘ç»œï¼Œä¸ºEGRç³»ç»Ÿçš„æ ¸å¿ƒæŽ¨ç†èƒ½åŠ›å¥ å®šäº†åŸºç¡€ã€‚

**æ ¸å¿ƒæˆå°±**:
1. âœ… å®Œæ•´çš„80åˆ†ç±»ç¥žç»ç½‘ç»œ
2. âœ… ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹
3. âœ… æ¸…æ™°çš„æŽ¨ç†æŽ¥å£
4. âœ… ä¸ºä¸‰å±‚ç†µæž¶æž„çš„Layer 1å®žçŽ°

**ä¸‹ä¸€æ­¥**:
- è¿è¡Œå®Œæ•´è®­ç»ƒ
- é›†æˆåˆ°æŽ¨ç†å¼•æ“Žï¼ˆModule 4ï¼‰
- å®žçŽ°ç†µä¼°è®¡å™¨å’Œä¿¡æ¯å¢žç›Šè®¡ç®—

---

**å®Œæˆæ—¥æœŸ**: 2026-01-20  
**ç»´æŠ¤è€…**: EGR Team  
**ç‰ˆæœ¬**: v1.0

---

## é™„å½•A: è®­ç»ƒå‘½ä»¤é€ŸæŸ¥

```bash
# æµ‹è¯•åŠŸèƒ½
python scripts/selector/test.py

# å®Œæ•´è®­ç»ƒ
python scripts/selector/train.py

# è‡ªå®šä¹‰è®­ç»ƒ
python -c "
from src.selector import train_model
train_model(
    data_path='data/train_state_model.json',
    num_epochs=50,
    batch_size=8,
    learning_rate=0.0005
)
"
```

## é™„å½•B: æ¨¡åž‹æ€§èƒ½åŸºå‡†

| æ•°æ®è§„æ¨¡ | Top-1 | Top-3 | Top-5 |
|---------|-------|-------|-------|
| 135æ ·æœ¬ | 20-30% | 40-50% | 50-60% |
| 1000æ ·æœ¬ï¼ˆé¢„ä¼°ï¼‰| 40-50% | 60-70% | 70-80% |
| 10000æ ·æœ¬ï¼ˆç›®æ ‡ï¼‰| 50-60% | 70-80% | 80%+ |

## é™„å½•C: ä¾èµ–ç‰ˆæœ¬

```
torch>=2.0.0
numpy>=1.24.0
sympy>=1.12
```
