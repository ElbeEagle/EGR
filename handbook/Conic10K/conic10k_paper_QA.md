
## 📊 **论文概览**

**标题**: Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset

**核心贡献**: 提出了一个专注于**圆锥曲线**（椭圆、双曲线、抛物线）的中国高中数学问题数据集，包含10,861个精心标注的问题。

---

## 🎯 **研究动机（为什么做这个工作）**

### 现有数学数据集的两大问题：

1. **推理步骤太少** 
   - 现有数据集（如Math23K、GSM8K）的问题只需2-3步推理就能解决
   - 模型可能依赖"浅层启发式"而非真正的推理能力

2. **主题分散，每个主题数据量小**
   - 如MATH数据集覆盖多个主题，但每个主题只有少量数据
   - **无法区分模型失败是因为缺乏知识还是推理能力不足**

### Conic10K的解决方案：

✅ **封闭知识域**：只涉及圆锥曲线知识  
✅ **长推理链**：平均4.23步推理（中文数据集中最长）  
✅ **高质量标注**：提供形式化表示、推理步骤、答案和自然语言解释

---

## 🏗️ **数据集构建过程**

### 1. **数据收集**
- 从两个中文高中教育网站收集约20,000个圆锥曲线问题（图片格式）
- 使用Mathpix将图片转换为LaTeX文本
- 过滤掉其他主题（数列、立体几何等）
- 去重后剩余约14,000个问题

### 2. **标注流程**（耗时4个月）

```
初始阶段
├─ 构建小型数据集（数百样本）
├─ 编写标注指南
└─ 开发基于规则的AI辅助工具

验证阶段
└─ 从候选人中选择表现最好的标注员

标注阶段
├─ 两名标注员独立标注每个问题
├─ 第三名验证员比对并验证
├─ 随机检查3%的标注
└─ 支付超过15万人民币（约2万美元）

最终化阶段
├─ 训练翻译模型（5折交叉验证）
├─ 人工检查不一致的地方
├─ 修正另外2%的数据
└─ 按7.5:1:2划分训练/验证/测试集
```

### 3. **形式化表示（Formal Representation）**

基于**断言逻辑（Assertional Logic）**设计，包含三个组件：

```python
# 示例问题的形式化表示结构

Declarations (声明个体及其类型)
G: Ellipse  # G是一个椭圆

Facts (描述问题条件的断言)
Focus(G) = {F1, F2}  # G的焦点是F1和F2
Eccentricity(G) = 1/2  # 离心率是1/2

Queries (问题目标)
Range(Eccentricity(G))  # 求离心率的范围
```

**设计原则**：
- 避免歧义
- 接近自然语言
- 简洁清晰（仅使用94个操作符和20个概念）

---

## 📈 **数据集统计**

| 指标 | 数值 |
|------|------|
| 问题总数 | 10,861 |
| 平均推理步数 | **4.23**（所有语言中第二长） |
| 平均LaTeX表达式数 | 5.76 |
| 平均Token数 | 83.43 |
| 平均形式化表示句子数 | 10.55 |

### 答案类型分布（6类）：
1. **简单数字** (Simple Number): 2, -1
2. **复杂数字** (Complex Number): 1/3, √5-1
3. **方程** (Equation): x²+y²/4=1
4. **坐标** (Coordinate): (0,1)
5. **区间和集合** (Interval & Set): [-1,1]
6. **文本** (Text): 'ellipse'

---

## 🧪 **实验设计**

### **两个评估任务**：

1. **语义解析 (Semantic Parsing)**
   - **目标**: 将自然语言数学问题翻译成形式化表示
   - **评估**: 模型的数学**理解**能力

2. **数学问答 (MathQA)**
   - **目标**: 直接给出问题的答案
   - **评估**: 模型的数学**理解+推理**能力

### **测试的模型**：

| 模型类别 | 具体模型 |
|---------|---------|
| 编码器-解码器 | mT5, mT0 (300M-3.7B) |
| 仅解码器 | LLaMA, Vicuna, Bloom, Bloomz (7B-176B) |
| 中文优化模型 | **ChatGLM-6B**, Ziya-13B |
| 闭源模型 | **GPT-3.5-turbo**, **GPT-4** |

### **实验设置**：
- **微调**: <4B模型全量微调，7B模型使用LoRA+8位量化
- **零样本CoT**: 7B-13B指令微调模型
- **人类专家基线**: 每题限时3分钟

---

## 🎯 **核心实验结果**

### ✅ **语义解析：表现良好**

| 模型 | 准确率 |
|------|--------|
| **mT0-xl (3.7B)** | **84.6%** |
| Vicuna-7b (LoRA) | 76.9% |
| ChatGLM-6b (LoRA) | 74.7% |

**关键发现**：
- 模型在理解数学问题方面表现不错
- 在代码上预训练的模型语法错误率更低
- 模型规模增大可显著提升性能（至少7.4%）

---

### ❌ **数学问答：表现不佳**



| 方法 | 最佳模型 | 准确率 |
|------|---------|--------|
| **微调** | ChatGLM-6b | **22.5%** |
| **零样本CoT** | GPT-4| **15.5%** |
| **GPT-4 (英文翻译)** | GPT-4 | **26.0%** |
| **人类专家** | - | **57.5%** |

#### **惊人的差距**：
- 即使是GPT-4，表现也远低于人类专家（26.0% vs 57.5%）
- 大多数模型在零样本CoT下准确率接近0
- Bloomz-7b和Falcon-7b-inst在零样本下准确率为**0%**

#### **不同答案类型的表现**：

```
微调后 ChatGLM-6b 的分类准确率：
├─ 简单数字：39.3% ✓ 最好
├─ 复杂数字：23.1%
├─ 方程：13.1%
├─ 坐标：10.6%
├─ 区间和集合：6.5%
└─ 文本：0.0% ✗ 最差

零样本 GPT-4 的分类准确率：
├─ 坐标：21.4% ✓ 最好
├─ 方程：20.4%
├─ 简单数字：17.8%
├─ 复杂数字：11.8%
└─ 区间和集合：5.3%
```

---

## 🔍 **深度分析（最重要的洞察）**

### 1️⃣ **模型在推理上的致命缺陷**

**现象**: 翻译成英文后GPT-4表现提升（15.5%→26.0%），但仍远低于人类

**结论**: ❗ **问题不在语言，而在推理能力本身**

---

### 2️⃣ **无法理解长LaTeX表达式**

**mT0-xl的9.7%错误**来自对长LaTeX表达式的理解错误：

```latex
原始: x^2+y^2+2√2x-4√2y+10-r^2=0

模型翻译成:
-4*sqrt(2)*y+2*sqrt(2)*x+x^2+y^2+2=-r^2
# ❌ 符号错误、常数项错误
```

---

### 3️⃣ **找不到捷径解法（最有趣的发现）**

GPT-4倾向于使用**笨拙的方法**解题，导致计算量增大、容易出错。

#### **案例1：抛物线最小值问题**

**问题**: 给定抛物线y²=4x上的点P，求|PA|+d的最小值（A(4,5)，d是P到y轴距离）

**GPT-4的笨方法**：
```python
# 设P(x₀, y₀)，y₀²=4x₀
# 计算 |PA| = √[(x₀-4)²+(y₀-5)²]
# 代入 y₀²=4x₀ 得：
|PA| = √[(x₀-4)²+(4x₀-5)²]  # ❌ 这步就算错了！

# 然后对 17x₀²-40x₀+41 求导...
# 得到错误答案：√(144/17)
```

**人类的捷径解法**：
```python
# 利用抛物线性质：点到焦点距离 = 点到准线距离
# |PA|+d = |PA|+|FP|-1  （F是焦点）
# ≥ |AF|-1 = √[(4-1)²+(5-0)²]-1
# = √34-1  ✓ 正确答案
```

---

#### **案例2：双曲线弦的中点问题**

**GPT-4方法**：假设两个对称点A、B，联立方程求解坐标，再求直线方程（复杂且算错）

**人类捷径**：利用中点性质，直接由 $\frac{x_1²-x_2²}{4}-(y_1²-y_2²)=0$ 推导斜率

---

### 4️⃣ **知识缺失**

**GPT-4对"焦距"的定义错误**：
- ❌ 模型理解：焦距 = 中心到一个焦点的距离
- ✅ 正确定义：焦距 = 两个焦点之间的距离

**原因推测**: "focal distance"在英语语料中不常见

---

### 5️⃣ **推理中的幻觉**

**ChatGLM-6b的错误推理**：

```
问题：抛物线 y²=8x 的焦点坐标？

ChatGLM推理：
"抛物线标准方程是 y²=4px  # ✓ 正确
所以 p=2                   # ✓ 正确
因此焦点x坐标是 p/2=1"     # ❌ 错误逻辑
```

实际上：y²=8x → y²=4×2x → p=2 → 焦点(p/2, 0)=(1,0)，结果碰巧对了，但推理过程是错的。

---

## 💡 **论文的核心发现总结**

1. ✅ **LLMs在数学理解上表现良好**（语义解析84.6%）
2. ❌ **LLMs在数学推理上表现糟糕**（最好22.5% vs 人类57.5%）
3. 🔍 **扩展定律在推理任务上不明显**（更大的模型≠更好的推理）
4. 🇨🇳 **中文优化模型在中文任务上更强**（ChatGLM表现最好）
5. 🧮 **模型不擅长找捷径解法**，倾向于暴力计算
6. 👻 **推理过程容易产生幻觉**

---

## 📝 **研究意义**

这项工作为AI社区提供了：

1. **可控的实验环境**：固定知识域 → 可独立评估推理能力
2. **高质量基准**：形式化表示 + 推理步骤 + 自然语言解释
3. **深刻洞察**：揭示了即使是GPT-4在复杂推理上的局限性

