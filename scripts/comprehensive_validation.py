"""
ç»¼åˆéªŒè¯è„šæœ¬

éªŒè¯å†…å®¹ï¼š
1. é›†æˆæµ‹è¯• - å®Œæ•´çŠ¶æ€åºåˆ—æ„å»º
2. æŒ‡æ ‡éªŒè¯ - completenesså•è°ƒé€’å¢ç­‰
3. æ¨¡å‹åº”ç”¨æ­£ç¡®æ€§
"""

import json
import sys
from pathlib import Path
from typing import List, Dict

# æ·»åŠ srcåˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.state import StateConstructor
from src.theorems import TheoremLibrary


def print_separator(title: str, char: str = "="):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print("\n" + char * 80)
    print(f"  {title}")
    print(char * 80 + "\n")


def validate_completeness_monotonicity(
    sample: dict,
    constructor: StateConstructor,
    library: TheoremLibrary
) -> Dict:
    """
    éªŒè¯å®Œæ•´åº¦å•è°ƒé€’å¢
    
    Returns:
        dict: éªŒè¯ç»“æœ
    """
    sample_id = sample['id']
    models = sample.get('models', [])
    
    if not models:
        return None
    
    # æ„å»ºåˆå§‹çŠ¶æ€
    abstract_state, symbolic_state = constructor.construct_from_facts(
        sample['fact_expressions'],
        sample['query_expressions'],
        reasoning_depth=0
    )
    
    completeness_sequence = [abstract_state.completeness_score]
    param_count_sequence = [len(symbolic_state.parameters)]
    
    # é€æ­¥åº”ç”¨æ¨¡å‹
    for i, model_id in enumerate(models):
        if not library.has_model(model_id):
            continue
        
        model = library.get_model(model_id)
        
        if not model.can_apply(symbolic_state):
            continue
        
        try:
            # è®°å½•åº”ç”¨å‰çš„çŠ¶æ€
            prev_params = len(symbolic_state.parameters)
            
            # åº”ç”¨æ¨¡å‹
            model.apply(symbolic_state)
            
            # é‡æ–°æ„å»ºæŠ½è±¡çŠ¶æ€
            abstract_state = constructor.construct_from_symbolic_state(
                symbolic_state,
                sample['query_expressions'],
                reasoning_depth=i + 1
            )
            
            # è®°å½•å®Œæ•´åº¦å’Œå‚æ•°æ•°é‡
            completeness_sequence.append(abstract_state.completeness_score)
            param_count_sequence.append(len(symbolic_state.parameters))
            
        except Exception as e:
            continue
    
    # æ£€æŸ¥å•è°ƒæ€§
    is_monotonic = all(
        completeness_sequence[i] <= completeness_sequence[i+1]
        for i in range(len(completeness_sequence) - 1)
    )
    
    # æ£€æŸ¥å‚æ•°æ•°é‡å•è°ƒæ€§
    params_monotonic = all(
        param_count_sequence[i] <= param_count_sequence[i+1]
        for i in range(len(param_count_sequence) - 1)
    )
    
    return {
        'sample_id': sample_id,
        'completeness_sequence': completeness_sequence,
        'param_count_sequence': param_count_sequence,
        'is_monotonic': is_monotonic,
        'params_monotonic': params_monotonic,
        'initial_completeness': completeness_sequence[0],
        'final_completeness': completeness_sequence[-1],
        'completeness_gain': completeness_sequence[-1] - completeness_sequence[0],
        'param_gain': param_count_sequence[-1] - param_count_sequence[0]
    }


def validate_state_construction_integrity(
    sample: dict,
    constructor: StateConstructor,
    library: TheoremLibrary
) -> Dict:
    """
    éªŒè¯çŠ¶æ€æ„å»ºçš„å®Œæ•´æ€§
    
    æ£€æŸ¥ï¼š
    1. SymbolicState å„å­—æ®µæ­£ç¡®å¡«å……
    2. AbstractState ç‰¹å¾æå–æ­£ç¡®
    3. çŠ¶æ€æ›´æ–°æ­£ç¡®
    """
    sample_id = sample['id']
    
    # æ„å»ºåˆå§‹çŠ¶æ€
    abstract_state, symbolic_state = constructor.construct_from_facts(
        sample['fact_expressions'],
        sample['query_expressions'],
        reasoning_depth=0
    )
    
    # æ£€æŸ¥ SymbolicState
    has_entities = len(symbolic_state.entities) > 0
    has_equations = len(symbolic_state.equations) > 0
    
    # æ£€æŸ¥ AbstractState
    curve_type_valid = abstract_state.curve_type is not None
    query_type_valid = abstract_state.query_type is not None
    completeness_valid = 0.0 <= abstract_state.completeness_score <= 1.0
    
    # åº”ç”¨æ¨¡å‹å¹¶æ£€æŸ¥æ›´æ–°
    models = sample.get('models', [])
    models_applied = []
    
    for model_id in models[:3]:  # æµ‹è¯•å‰3ä¸ªæ¨¡å‹
        if not library.has_model(model_id):
            continue
        
        model = library.get_model(model_id)
        
        if not model.can_apply(symbolic_state):
            continue
        
        try:
            prev_applied = len(symbolic_state.applied_models)
            model.apply(symbolic_state)
            
            # æ£€æŸ¥ applied_models æ›´æ–°
            if len(symbolic_state.applied_models) > prev_applied:
                models_applied.append(model_id)
        except:
            continue
    
    return {
        'sample_id': sample_id,
        'has_entities': has_entities,
        'has_equations': has_equations,
        'curve_type_valid': curve_type_valid,
        'query_type_valid': query_type_valid,
        'completeness_valid': completeness_valid,
        'models_applied': len(models_applied),
        'all_valid': all([
            has_entities,
            has_equations,
            curve_type_valid,
            query_type_valid,
            completeness_valid
        ])
    }


def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®è·¯å¾„
    data_path = project_root / "data" / "train_with_models_1_100.json"
    
    print_separator("ç»¼åˆéªŒè¯æµ‹è¯•", "=")
    print(f"æ•°æ®è·¯å¾„: {data_path}")
    
    # åŠ è½½æ•°æ®
    print("\næ­£åœ¨åŠ è½½æ•°æ®...")
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    print(f"âœ“ åŠ è½½å®Œæˆï¼Œå…± {len(data)} ä¸ªæ ·æœ¬")
    
    # åˆ›å»ºå®šç†åº“å’Œæ„é€ å™¨
    library = TheoremLibrary()
    constructor = StateConstructor(theorem_library=library)
    
    print(f"\nå®šç†åº“çŠ¶æ€: {library}")
    
    # ========================================================================
    # æµ‹è¯•1: å®Œæ•´åº¦å•è°ƒæ€§éªŒè¯
    # ========================================================================
    print_separator("æµ‹è¯•1: å®Œæ•´åº¦å•è°ƒæ€§éªŒè¯", "-")
    
    monotonicity_results = []
    for sample in data:
        if not sample.get('models'):
            continue
        
        result = validate_completeness_monotonicity(sample, constructor, library)
        if result:
            monotonicity_results.append(result)
        
        if len(monotonicity_results) >= 10:
            break
    
    # ç»Ÿè®¡ç»“æœ
    monotonic_count = sum(1 for r in monotonicity_results if r['is_monotonic'])
    params_monotonic_count = sum(1 for r in monotonicity_results if r['params_monotonic'])
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(monotonicity_results)}")
    print(f"å®Œæ•´åº¦å•è°ƒé€’å¢: {monotonic_count}/{len(monotonicity_results)} ({monotonic_count/len(monotonicity_results)*100:.1f}%)")
    print(f"å‚æ•°æ•°é‡å•è°ƒé€’å¢: {params_monotonic_count}/{len(monotonicity_results)} ({params_monotonic_count/len(monotonicity_results)*100:.1f}%)")
    
    # è¯¦ç»†ç»“æœ
    print("\næ ·æœ¬è¯¦æƒ…:")
    print(f"{'æ ·æœ¬ID':<8} {'åˆå§‹':<8} {'æœ€ç»ˆ':<8} {'å¢ç›Š':<8} {'å‚æ•°å¢ç›Š':<8} {'å•è°ƒæ€§':<8}")
    print("-" * 60)
    for r in monotonicity_results:
        monotonic_str = "âœ…" if r['is_monotonic'] else "âŒ"
        print(f"{r['sample_id']:<8} {r['initial_completeness']:<8.2f} {r['final_completeness']:<8.2f} "
              f"{r['completeness_gain']:<8.2f} {r['param_gain']:<8} {monotonic_str:<8}")
    
    # å¹³å‡å¢ç›Š
    avg_gain = sum(r['completeness_gain'] for r in monotonicity_results) / len(monotonicity_results)
    avg_param_gain = sum(r['param_gain'] for r in monotonicity_results) / len(monotonicity_results)
    print(f"\nå¹³å‡å®Œæ•´åº¦å¢ç›Š: {avg_gain:.2f}")
    print(f"å¹³å‡å‚æ•°å¢ç›Š: {avg_param_gain:.1f}")
    
    # ========================================================================
    # æµ‹è¯•2: çŠ¶æ€æ„å»ºå®Œæ•´æ€§éªŒè¯
    # ========================================================================
    print_separator("æµ‹è¯•2: çŠ¶æ€æ„å»ºå®Œæ•´æ€§éªŒè¯", "-")
    
    integrity_results = []
    for sample in data:
        if not sample.get('models'):
            continue
        
        result = validate_state_construction_integrity(sample, constructor, library)
        if result:
            integrity_results.append(result)
        
        if len(integrity_results) >= 10:
            break
    
    # ç»Ÿè®¡ç»“æœ
    all_valid_count = sum(1 for r in integrity_results if r['all_valid'])
    
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(integrity_results)}")
    print(f"çŠ¶æ€æ„å»ºå®Œå…¨æœ‰æ•ˆ: {all_valid_count}/{len(integrity_results)} ({all_valid_count/len(integrity_results)*100:.1f}%)")
    
    # è¯¦ç»†ç»“æœ
    print("\næ ·æœ¬è¯¦æƒ…:")
    print(f"{'æ ·æœ¬ID':<8} {'å®ä½“':<6} {'æ–¹ç¨‹':<6} {'æ›²çº¿':<6} {'æŸ¥è¯¢':<6} {'å®Œæ•´åº¦':<8} {'æ¨¡å‹åº”ç”¨':<8} {'çŠ¶æ€':<6}")
    print("-" * 70)
    for r in integrity_results:
        status = "âœ…" if r['all_valid'] else "âŒ"
        print(f"{r['sample_id']:<8} "
              f"{'âœ“' if r['has_entities'] else 'âœ—':<6} "
              f"{'âœ“' if r['has_equations'] else 'âœ—':<6} "
              f"{'âœ“' if r['curve_type_valid'] else 'âœ—':<6} "
              f"{'âœ“' if r['query_type_valid'] else 'âœ—':<6} "
              f"{'âœ“' if r['completeness_valid'] else 'âœ—':<8} "
              f"{r['models_applied']:<8} "
              f"{status:<6}")
    
    # ========================================================================
    # æµ‹è¯•3: é›†æˆæµ‹è¯•æ€»ç»“
    # ========================================================================
    print_separator("æµ‹è¯•3: é›†æˆæµ‹è¯•æ€»ç»“", "-")
    
    print("âœ… å®Œæ•´åº¦å•è°ƒæ€§:")
    if monotonic_count == len(monotonicity_results):
        print("   âœ“ æ‰€æœ‰æ ·æœ¬å®Œæ•´åº¦å•è°ƒé€’å¢")
    else:
        print(f"   âš ï¸  {len(monotonicity_results) - monotonic_count} ä¸ªæ ·æœ¬å®Œæ•´åº¦éå•è°ƒ")
    
    print("\nâœ… å‚æ•°æ•°é‡å•è°ƒæ€§:")
    if params_monotonic_count == len(monotonicity_results):
        print("   âœ“ æ‰€æœ‰æ ·æœ¬å‚æ•°æ•°é‡å•è°ƒé€’å¢")
    else:
        print(f"   âš ï¸  {len(monotonicity_results) - params_monotonic_count} ä¸ªæ ·æœ¬å‚æ•°æ•°é‡éå•è°ƒ")
    
    print("\nâœ… çŠ¶æ€æ„å»ºå®Œæ•´æ€§:")
    if all_valid_count == len(integrity_results):
        print("   âœ“ æ‰€æœ‰æ ·æœ¬çŠ¶æ€æ„å»ºå®Œå…¨æœ‰æ•ˆ")
    else:
        print(f"   âš ï¸  {len(integrity_results) - all_valid_count} ä¸ªæ ·æœ¬çŠ¶æ€æ„å»ºå­˜åœ¨é—®é¢˜")
    
    # ========================================================================
    # æœ€ç»ˆç»“è®º
    # ========================================================================
    print_separator("æœ€ç»ˆç»“è®º", "=")
    
    all_tests_passed = (
        monotonic_count >= len(monotonicity_results) * 0.9 and  # 90%ä»¥ä¸Šå•è°ƒ
        params_monotonic_count >= len(monotonicity_results) * 0.9 and
        all_valid_count == len(integrity_results)  # 100%æœ‰æ•ˆ
    )
    
    if all_tests_passed:
        print("ğŸ‰ æ‰€æœ‰éªŒè¯æµ‹è¯•é€šè¿‡ï¼")
        print("\nâœ… å®Œæ•´åº¦å•è°ƒæ€§: ä¼˜ç§€")
        print("âœ… å‚æ•°æ•°é‡å•è°ƒæ€§: ä¼˜ç§€")
        print("âœ… çŠ¶æ€æ„å»ºå®Œæ•´æ€§: å®Œç¾")
        print("\nç³»ç»Ÿæ¶æ„ç¨³å®šï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µå¼€å‘ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†éªŒè¯æµ‹è¯•æœªé€šè¿‡")
        print("\néœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–çš„æ–¹é¢:")
        if monotonic_count < len(monotonicity_results) * 0.9:
            print("  - å®Œæ•´åº¦å•è°ƒæ€§éœ€è¦æ”¹è¿›")
        if params_monotonic_count < len(monotonicity_results) * 0.9:
            print("  - å‚æ•°æå–æœºåˆ¶éœ€è¦ä¼˜åŒ–")
        if all_valid_count < len(integrity_results):
            print("  - çŠ¶æ€æ„å»ºå­˜åœ¨é—®é¢˜")
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
